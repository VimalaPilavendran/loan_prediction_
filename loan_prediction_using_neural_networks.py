# -*- coding: utf-8 -*-
"""Loan Prediction using neural networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wke5R7x_WyGmMjhPR4omDna9PpkTauyj
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

data = pd.read_csv("train.csv")

data.head()

data.info()

# Checking Null Values
data.isnull().sum()

# Handling Categorical Null Values 
data['Gender'].fillna(data['Gender'].mode()[0],
                      inplace = True)
data['Married'].fillna(data['Married'].mode()[0],
                       inplace = True)
data['Dependents'].fillna(data['Dependents'].mode()[0],
                         inplace = True)
data['Education'].fillna(data['Education'].mode()[0],
                         inplace = True)
data['Self_Employed'].fillna(data['Self_Employed'].mode()[0],
                             inplace = True)

plt.figure(figsize = (10,4))
sns.boxplot(x = 'LoanAmount',
            data = data,
            orient = 'horizontal')
plt.show()

data['LoanAmount'].fillna(data['LoanAmount'].median(),
                          inplace = True)

# Converting the categories into numbers using map function.
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
data['Married'] = data['Married'].map({'No': 0, 'Yes': 1})
data['Dependents'] = data['Dependents'].map({'0': 0, '1': 1, '2': 2, '3+': 3})
data['Education'] = data['Education'].map({'Graduate': 1, 'Not Graduate': 0})
data['Self_Employed'] = data['Self_Employed'].map({'No': 0, 'Yes': 1})
data['Property_Area'] = data['Property_Area'].map({'Rural': 0, 'Semiurban': 1, 'Urban': 2})
data['Loan_Status'] = data['Loan_Status'].map({'N': 0, 'Y': 1})

#scaling the values-Min Max scaler
for i in data.columns[1:]:
    data[i] = (data[i] - data[i].min()) / (data[i].max() - data[i].min())

X = data.iloc[:,1:12].values
y = data.iloc[:,12].values

X

y

#Steps to build Neural Network
#Creating training and validation data
# Testing Data - 10%
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify=data['Loan_Status'], random_state = 42)
# Train & Valid Data - 90%
x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = y_train, random_state = 42)

# Creating a skeleton of model.
from keras.models import Sequential
# Defining layers
from keras.layers import Input, Dense
from tensorflow.keras.layers import InputLayer

# Input neurons
input_neurons = X_train.shape[1]
# Output neurons (Since it is binary classification)
output_neurons = 1
# Defining hidden layers & neurons in each layersnumber_of_hidden_layers = 2
neuron_hidden_layer_1         = 20
neuron_hidden_layer_2         = 15
neuron_hidden_layer_3         = 10
neuron_hidden_layer_4         = 5
# Defining the architecture of the model
model = Sequential()
model.add(InputLayer(input_shape=(input_neurons)))
model.add(Dense(units=neuron_hidden_layer_1, activation='relu'))
model.add(Dense(units=neuron_hidden_layer_2, activation='relu'))
model.add(Dense(units=neuron_hidden_layer_3, activation='relu'))
model.add(Dense(units=neuron_hidden_layer_4, activation='relu'))
model.add(Dense(units=output_neurons, activation='sigmoid'))

#compiling the model
model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])

#Training the model
model_history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 50)

# Getting predictions for the test set
y_predict = np.argmax(model.predict(X_test), axis=-1)

# Getting accuracy score
from sklearn.metrics import accuracy_score
print("Accuracy_Score : {}".format(accuracy_score(y_predict, y_test) * 265))